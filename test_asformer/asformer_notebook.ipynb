{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "sys.path.insert(1, os.path.split(os.getcwd())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataloader import DataLoader\n",
    "from model import Trainer\n",
    "from utils.utils import create_folders\n",
    "from batch_gen import BatchGenerator\n",
    "\n",
    "import torch \n",
    "\n",
    "from asformer import MyTransformer, ASFormerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(): \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.train_data = 'bslcp'\n",
    "        self.test_data = 'bslcp'\n",
    "        self.i3d_training = 'i3d_kinetics_bslcp_981'\n",
    "        self.num_in_frames = 16\n",
    "        self.features_dim = 1024\n",
    "        self.weights = 'opt'\n",
    "        self.regression = 0 \n",
    "        self.feature_normalization = 0\n",
    "        self.eval_use_CP = 0\n",
    "\n",
    "        self.action = 'train'\n",
    "        self.seed = 0 \n",
    "        self.refresh = 'store_true'\n",
    "\n",
    "        ## Transformer : \n",
    "        self.nhead = 4\n",
    "        self.nhid = 1024\n",
    "        self.dim_feedforward = 1024\n",
    "        self.num_layers = 6\n",
    "        self.dropout = 0\n",
    "\n",
    "        ## MSTCN : \n",
    "        self.num_stages = 4\n",
    "        self.num_layers = 10 \n",
    "        self.num_f_maps = 64\n",
    "        self.features_dim = 1024\n",
    "        self.bz = 8 \n",
    "        self.lr = 0.0005\n",
    "        self.lr_mul = 1\n",
    "        self.num_epochs = 50\n",
    "        self.extract_epoch = 10 \n",
    "        self.classification_threshold = 0.5\n",
    "\n",
    "        ## ASFormer : \n",
    "        self.num_layers = 7\n",
    "        self.num_decoders = 3\n",
    "        self.r1 = 2\n",
    "        self.r2 = 2\n",
    "        self.channel_masking_rate = 0.3\n",
    "        self.input_dim = 1024\n",
    "        self.num_f_maps = 64\n",
    "        \n",
    "        \n",
    "        ## Optimization\n",
    "        self.n_warmup_steps = 100\n",
    "        ## save model : \n",
    "        self.use_pseudo_labels = 'store_true'\n",
    "        self.pretrained = False\n",
    "        self.folder = ''\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train data: bslcp\n",
      "Load test data: bslcp\n"
     ]
    }
   ],
   "source": [
    "# load train dataset and test dataset\n",
    "\n",
    "print(f'Load train data: {args.train_data}')\n",
    "train_loader = DataLoader(args, args.train_data, 'train')\n",
    "print(f'Load test data: {args.test_data}')\n",
    "test_loader = DataLoader(args, args.test_data, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved options to ./exps//models/classification/traindata_bslcp/i3d_kinetics_bslcp_981/supervised/7_(7,)_(64,)_8_0.0005_weighted_opt/seed_0\\opt.txt\n",
      "./exps//models/classification/traindata_bslcp/i3d_kinetics_bslcp_981/supervised/7_(7,)_(64,)_8_0.0005_weighted_opt/seed_0\n"
     ]
    }
   ],
   "source": [
    "model_load_dir, model_save_dir, results_save_dir = create_folders(args)\n",
    "print(model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS Former model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size:  762888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 238, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 531, in write\n",
      "    self.fs.write(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 148, in write\n",
      "    self._write(filename, file_content, \"wb\" if binary_mode else \"w\")\n",
      "  File \"C:\\Users\\kam_a\\.conda\\envs\\signseg_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 162, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'./exps//models/classification/traindata_bslcp/i3d_kinetics_bslcp_981/supervised/7_(7,)_(64,)_8_0.0005_weighted_opt/seed_0/logs\\\\events.out.tfevents.1642871942.DESKTOP-M7GVU52.26252.0'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = ASFormerTrainer(args.num_decoders,args.num_layers, args.r1, args.r2, args.num_f_maps, args.input_dim, 2, args.channel_masking_rate, train_loader.weights, model_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_args = [\n",
    "    args,\n",
    "    model_save_dir,\n",
    "    results_save_dir,\n",
    "    test_loader.features_dict,\n",
    "    test_loader.gt_dict,\n",
    "    test_loader.eval_gt_dict,\n",
    "    test_loader.vid_list,\n",
    "    args.num_epochs,\n",
    "    device,\n",
    "    'eval',\n",
    "    args.classification_threshold,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_gen = BatchGenerator(\n",
    "        train_loader.num_classes,\n",
    "        train_loader.gt_dict,\n",
    "        train_loader.features_dict,\n",
    "        train_loader.eval_gt_dict\n",
    "        )\n",
    "\n",
    "batch_gen.read_data(train_loader.vid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:0.0005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26252/2342027847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_save_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\kam_a\\OneDrive\\Bureau\\MVA\\RecVis\\RecVisProject\\MVARecVisProject\\asformer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, save_dir, batch_gen, num_epochs, batch_size, learning_rate, eval_args)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\signseg_env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\signseg_env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(model_save_dir, batch_gen, 15, 1, 0.0005, eval_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d95d6b7a3c173ab153c673ec402a2591ade3b55cc535db1e60390b48c1dd47f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('signseg_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
